import pandas as pd
import json
import os
from datetime import datetime

def export_to_json(input_path="data/candidates_c.csv", output_path="data/data.json"):
    print("ğŸ“ Module D: Generating AI Report...")
    
    logs = []
    stats = {"universe": 0, "s1_filtered": 0, "s2_checked": 0, "final_ready": 0}

    # Step A, B ìƒëµ (ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ë¯€ë¡œ ë¡œê·¸ ë¡œì§ ìœ ì§€ëœë‹¤ê³  ê°€ì •í•˜ê³  í•µì‹¬ë§Œ ì‘ì„±)
    # ì‹¤ì œ íŒŒì¼ì—ëŠ” Step A, B í™•ì¸ ë¡œì§ì´ ìˆì–´ì•¼ í•˜ì§€ë§Œ, ì½”ë“œ ê¸¸ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•´
    # ì§€íœ˜ê´€ë‹˜ì´ ì“°ì‹œë˜ ê¸°ì¡´ module_d_writer.pyì˜ ì•ë¶€ë¶„(ë¡œê·¸ ìˆ˜ì§‘)ì€ ê·¸ëŒ€ë¡œ ë‘ê³ 
    # ì•„ë˜ [ë°ì´í„° ë§¤í•‘] ë¶€ë¶„ë§Œ ë°”ë€ŒëŠ” ê²ƒì´ ì›ì¹™ì…ë‹ˆë‹¤.
    # í•˜ì§€ë§Œ ë³µì¡í•¨ì„ í”¼í•˜ê¸° ìœ„í•´ 'ì „ì²´ ì½”ë“œ'ë¥¼ ë“œë¦½ë‹ˆë‹¤.
    
    # [ë¡œê·¸ ìˆ˜ì§‘ - ì•½ì‹ ë³µì›]
    if os.path.exists("data/universe.csv"): stats['universe'] = len(pd.read_csv("data/universe.csv"))
    if os.path.exists("data/candidates_b.csv"): stats['s1_filtered'] = len(pd.read_csv("data/candidates_b.csv"))
    
    candidates = []
    if os.path.exists(input_path):
        try:
            df = pd.read_csv(input_path)
            stats['s2_checked'] = len(df)
            
            if not df.empty:
                logs.append(f"âœ… [Step 3] AI Analysis: {len(df)} candidates rated.")
                
                for _, row in df.iterrows():
                    rec_rate = row.get('recovery_rate', 0) / 100.0
                    
                    # íƒœê·¸ ë¡œì§: ë°˜ë“± 10% ì´ìƒì´ë©´ì„œ ê°ì„± ì ìˆ˜ê°€ ë„ˆë¬´ ë‚˜ì˜ì§€ ì•Šì•„ì•¼ í•¨(-0.5 ì´ìƒ)
                    sent_score = row.get('sentiment_score', 0)
                    
                    tag = "WATCH"
                    if rec_rate >= 0.10 and sent_score > -0.5:
                        tag = "READY"
                    
                    if tag == "READY": stats['final_ready'] += 1
                    
                    # ë°ì´í„° ë§¤í•‘ (ë§í¬ì™€ ì ìˆ˜ ì¶”ê°€)
                    news_text = row.get('news_top', 'No Data')
                    if pd.isna(news_text): news_text = "No Data"

                    candidate = {
                        "ticker": str(row['ticker']),
                        "price": float(row['price']),
                        "metrics": {
                            "drop_rate": row.get('drop_rate', 0),
                            "rec_rate": rec_rate
                        },
                        "evidence": {
                            "s4_tag": tag,
                            "ai_score": float(sent_score) # AI ì ìˆ˜
                        },
                        "context": {
                            "title": str(news_text),
                            "url": str(row.get('news_link', '#')) # ë‰´ìŠ¤ ë§í¬
                        }
                    }
                    candidates.append(candidate)
        except Exception as e:
            logs.append(f"âŒ Error: {str(e)}")
    
    data = {
        "metadata": {
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S KST"),
            "pipeline_stats": stats,
            "system_logs": logs
        },
        "candidates": candidates
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)
    
    return True
