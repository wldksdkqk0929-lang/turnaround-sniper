import pandas as pd
import requests
import xml.etree.ElementTree as ET
import time
import os
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

def get_google_news_data(ticker):
    # êµ¬ê¸€ ë‰´ìŠ¤ RSS (7ì¼ê°„)
    url = f"https://news.google.com/rss/search?q={ticker}+stock+when:7d&hl=en-US&gl=US&ceid=US:en"
    
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            items = root.findall('./channel/item')
            
            if not items:
                return "No recent news", "", 0
            
            # ìµœì‹  ë‰´ìŠ¤ 1ê±´ë§Œ ì§‘ì¤‘ ë¶„ì„
            item = items[0]
            title = item.find('title').text
            link = item.find('link').text
            
            # ì–¸ë¡ ì‚¬ ì´ë¦„ ì œê±° (ê¹”ë”í•˜ê²Œ)
            if "-" in title:
                title = title.split("-")[0].strip()
                
            return title, link, len(items)
            
    except Exception as e:
        return f"Error: {str(e)}", "", 0
    
    return "No Data", "", 0

def analyze_news(input_path="data/candidates_b.csv", output_path="data/candidates_c.csv"):
    if not os.path.exists(input_path):
        print("âŒ Module C: Input file not found.")
        return False
        
    df = pd.read_csv(input_path)
    if df.empty:
        df.to_csv(output_path, index=False)
        return True

    # NLTK ê°ì„±ë¶„ì„ê¸° ì¤€ë¹„ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ)
    try:
        nltk.data.find('sentiment/vader_lexicon.zip')
    except LookupError:
        nltk.download('vader_lexicon', quiet=True)
    
    sia = SentimentIntensityAnalyzer()
    
    results = []
    risk_words = ['bankruptcy', 'chapter 11', 'delisting', 'fraud', 'investigation']

    print(f"ðŸ§  Module C: AI Sentiment Analysis for {len(df)} stocks...")

    for i, row in df.iterrows():
        ticker = row['ticker']
        
        # 1. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        title, link, count = get_google_news_data(ticker)
        
        # 2. ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ 1ì°¨ í•„í„°
        risk_found = False
        for risk in risk_words:
            if risk in title.lower():
                risk_found = True
                print(f"   ðŸ”» Filtered {ticker}: Risk '{risk}' detected.")
                break
        
        if not risk_found:
            # 3. AI ê°ì„± ì ìˆ˜ ê³„ì‚° (-1.0 ~ +1.0)
            # ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ì ìˆ˜ 0 (ì¤‘ë¦½)
            if title == "No recent news" or title == "No Data":
                score = 0
            else:
                score = sia.polarity_scores(title)['compound']
            
            row['news_top'] = title
            row['news_link'] = link
            row['sentiment_score'] = score
            
            results.append(row)
            
            # ë¡œê·¸: ì ìˆ˜ì— ë”°ë¼ ì´ëª¨ì§€ ë‹¤ë¥´ê²Œ í‘œì‹œ
            emoji = "ðŸ˜"
            if score > 0.3: emoji = "ðŸ˜Š"
            elif score < -0.3: emoji = "ðŸ˜¨"
            
            print(f"   [{ticker}] {emoji} Score: {score:.2f} | {title[:30]}...")
        
        time.sleep(0.3)

    pd.DataFrame(results).to_csv(output_path, index=False)
    print(f"âœ… Module C: Analysis complete. {len(results)} stocks rated.")
    return True
